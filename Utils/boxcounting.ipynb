{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/a/akshatha.mohan/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/grads/a/akshatha.mohan/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import manifold\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "import pdb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9., 11.,  8., 20.],\n",
       "          [18., 18., 17.,  3.],\n",
       "          [10.,  7., 18., 16.],\n",
       "          [18., 17., 22., 13.]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "image = torch.tensor([[9, 11, 8, 20], [18, 18, 17, 3], [10, 7, 18, 16], [18, 17, 22, 13]], dtype=torch.float32)\n",
    "image = image.unsqueeze(0).unsqueeze(0)\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor(2)\n",
      "5\n",
      "tensor(5)\n",
      "4\n",
      "tensor(4)\n",
      "6\n",
      "tensor(6)\n",
      "[tensor(0.5000), tensor(0.2000), tensor(0.2500), tensor(0.1667)]\n",
      "[tensor(0.5000), tensor(0.2500), tensor(0.2000), tensor(0.1667)]\n"
     ]
    }
   ],
   "source": [
    "r = 3\n",
    "window_size = 3\n",
    "\n",
    "# Extract 2x2 horizontal windows\n",
    "windows_horizontal = []\n",
    "Lr_all_horizontal = []\n",
    "\n",
    "for i in range(image.size(2) - window_size + 1):\n",
    "    for j in range(image.size(3) - window_size + 1):\n",
    "        window = image[:, :, i:i+window_size, j:j+window_size]\n",
    "        windows_horizontal.append(window)\n",
    "\n",
    "        max_pool = nn.MaxPool2d(kernel_size=window.shape[2])\n",
    "        max_pool_output = max_pool(window)\n",
    "        min_pool_output = -max_pool(-window)\n",
    "        nr = math.ceil(max_pool_output.item() / r) - math.ceil(min_pool_output.item() / r) - 1\n",
    "        print(nr)\n",
    "        Mr = torch.sum(torch.tensor(nr))\n",
    "        Q_mr = nr / (window_size - r + 1)\n",
    "        print(Mr)\n",
    "        L_r = (Mr.item()**2) * Q_mr / (Mr * Q_mr)**2\n",
    "        Lr_all_horizontal.append(L_r)\n",
    "\n",
    "# Extract 2x2 vertical windows\n",
    "windows_vertical = []\n",
    "Lr_all_vertical = []\n",
    "\n",
    "for j in range(image.size(3) - window_size + 1):\n",
    "    for i in range(image.size(2) - window_size + 1):\n",
    "        window = image[:, :, i:i+window_size, j:j+window_size]\n",
    "        windows_vertical.append(window)\n",
    "\n",
    "        max_pool = nn.MaxPool2d(kernel_size=window.shape[2])\n",
    "        max_pool_output = max_pool(window)\n",
    "        min_pool_output = -max_pool(-window)\n",
    "        nr = math.ceil(max_pool_output.item() / r) - math.ceil(min_pool_output.item() / r) - 1\n",
    "        Mr = torch.sum(torch.tensor(nr))\n",
    "        Q_mr = nr / (window_size - r + 1)\n",
    "        L_r = (Mr.item()**2) * Q_mr / (Mr * Q_mr)**2\n",
    "        Lr_all_vertical.append(L_r)\n",
    "\n",
    "print(Lr_all_horizontal)\n",
    "print(Lr_all_vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2500, 0.1250, 0.1000, 0.0833],\n",
      "          [0.1000, 0.0500, 0.0400, 0.0333],\n",
      "          [0.1250, 0.0625, 0.0500, 0.0417],\n",
      "          [0.0833, 0.0417, 0.0333, 0.0278]]]])\n"
     ]
    }
   ],
   "source": [
    "# Combine results to create a 9x9 matrix\n",
    "Lr_horizontal_array = np.stack([tensor.numpy() for tensor in Lr_all_horizontal])\n",
    "Lr_vertical_array = np.stack([tensor.numpy() for tensor in Lr_all_vertical])\n",
    "combined_matrix = np.outer(Lr_horizontal_array, Lr_vertical_array)\n",
    "combined_matrix = torch.tensor(combined_matrix)\n",
    "combined_matrix = combined_matrix.unsqueeze(0).unsqueeze(0)\n",
    "print(combined_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "maximum size for tensor at dimension 1 is 1 but size is 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[39m# Assuming 'your_image_tensor' is your input tensor\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m result \u001b[39m=\u001b[39m custom_pooling_layer(image)\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mCustomPoolingLayer.forward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     13\u001b[0m windows_horizontal \u001b[39m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m Lr_all_horizontal \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 16\u001b[0m window \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39munfold(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(window)\n\u001b[1;32m     18\u001b[0m windows_horizontal\u001b[39m.\u001b[39mappend(window)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: maximum size for tensor at dimension 1 is 1 but size is 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        windows_horizontal = []\n",
    "        Lr_all_horizontal = []\n",
    "\n",
    "        window = image.unfold(1,3,1)\n",
    "        print(window)\n",
    "        windows_horizontal.append(window)\n",
    "\n",
    "        max_pool = nn.MaxPool2d(kernel_size=window.shape[2])\n",
    "        max_pool_output = max_pool(window)\n",
    "        min_pool_output = -max_pool(-window)\n",
    "        nr = math.ceil(max_pool_output / self.r) - math.ceil(min_pool_output / self.r) - 1\n",
    "        Mr = torch.sum(torch.tensor(nr))\n",
    "        Q_mr = nr / (self.window_size - self.r + 1)\n",
    "        L_r = (Mr.item()**2) * Q_mr / (Mr * Q_mr)**2\n",
    "        Lr_all_horizontal.append(L_r)\n",
    "\n",
    "        windows_vertical = []\n",
    "        Lr_all_vertical = []\n",
    "\n",
    "        for j in range(image.size(3) - self.window_size + 1):\n",
    "            for i in range(image.size(2) - self.window_size + 1):\n",
    "                window = image[:, :, i:i+self.window_size, j:j+self.window_size]\n",
    "                windows_vertical.append(window)\n",
    "\n",
    "                max_pool = nn.MaxPool2d(kernel_size=window.shape[2])\n",
    "                max_pool_output = max_pool(window)\n",
    "                min_pool_output = -max_pool(-window)\n",
    "                nr = math.ceil(max_pool_output / self.r) - math.ceil(min_pool_output / self.r) - 1\n",
    "                Mr = torch.sum(torch.tensor(nr))\n",
    "                Q_mr = nr / (self.window_size - self.r + 1)\n",
    "                L_r = (Mr.item()**2) * Q_mr / (Mr * Q_mr)**2\n",
    "                Lr_all_vertical.append(L_r)\n",
    "\n",
    "        Lr_horizontal_array = np.stack([tensor.numpy() for tensor in Lr_all_horizontal])\n",
    "        Lr_vertical_array = np.stack([tensor.numpy() for tensor in Lr_all_vertical])\n",
    "        combined_matrix = np.outer(Lr_horizontal_array, Lr_vertical_array)\n",
    "        combined_matrix = torch.tensor(combined_matrix)\n",
    "        combined_matrix = combined_matrix.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        return combined_matrix\n",
    "\n",
    "# Example usage:\n",
    "# Create an instance of the CustomPoolingLayer\n",
    "custom_pooling_layer = CustomPoolingLayer(r=3, window_size=3)\n",
    "image = image = torch.tensor([[9, 11, 8, 20], [18, 18, 17, 3], [10, 7, 18, 16], [18, 17, 22, 13]], dtype=torch.float32)\n",
    "image = image.unsqueeze(0).unsqueeze(0)\n",
    "# Assuming 'your_image_tensor' is your input tensor\n",
    "result = custom_pooling_layer(image)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
