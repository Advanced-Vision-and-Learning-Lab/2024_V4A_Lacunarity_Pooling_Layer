{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/a/akshatha.mohan/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/grads/a/akshatha.mohan/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import manifold\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "import pdb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 9., 11.,  8., 20.],\n",
       "          [18., 18., 17.,  3.],\n",
       "          [10.,  7., 18., 16.],\n",
       "          [18., 17., 22., 13.]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "image = torch.tensor([[9, 11, 8, 20], [18, 18, 17, 3], [10, 7, 18, 16], [18, 17, 22, 13]], dtype=torch.float32)\n",
    "image = image.unsqueeze(0).unsqueeze(0)\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0006]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pdb\n",
    "\n",
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        image_scaled = image * 255\n",
    "        windows_horizontal = []\n",
    "        Lr_all_horizontal = []\n",
    "\n",
    "        for i in range(image_scaled.size(2) - self.window_size + 1):\n",
    "            for j in range(image_scaled.size(3) - self.window_size + 1):\n",
    "                window = image_scaled[:, :, i:i+self.window_size, j:j+self.window_size]\n",
    "                windows_horizontal.append(window)\n",
    "\n",
    "                max_pool = nn.MaxPool2d(kernel_size=self.window_size)\n",
    "                max_pool_output = max_pool(window)\n",
    "                min_pool_output = -max_pool(-window)\n",
    "\n",
    "                nr = torch.ceil(max_pool_output / self.r) - torch.ceil(min_pool_output / self.r) - 1\n",
    "                Mr = torch.sum(nr)\n",
    "                Q_mr = nr / (self.window_size - self.r + 1)\n",
    "                L_r = (Mr**2) * Q_mr / (Mr * Q_mr)**2\n",
    "\n",
    "        return L_r\n",
    "\n",
    "# Example usage:\n",
    "# Create an instance of the CustomPoolingLayer\n",
    "custom_pooling_layer = CustomPoolingLayer(r=3, window_size=3)\n",
    "result = custom_pooling_layer(image)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3, 3])\n",
      "tensor([[[[0.5000]],\n",
      "\n",
      "         [[0.2000]]],\n",
      "\n",
      "\n",
      "        [[[0.2500]],\n",
      "\n",
      "         [[0.1667]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        windows_horizontal = image.unfold(2, self.window_size, 1).unfold(3, self.window_size, 1)\n",
    "        windows_horizontal = windows_horizontal.squeeze(0).squeeze(0)\n",
    "        print(windows_horizontal.shape)\n",
    "        max_pool = nn.MaxPool2d(kernel_size=self.window_size)\n",
    "        max_pool_output = max_pool(windows_horizontal)\n",
    "        min_pool_output = -max_pool(-windows_horizontal)\n",
    "\n",
    "        nr = torch.ceil(max_pool_output / self.r) - torch.ceil(min_pool_output / self.r) - 1\n",
    "        Mr = torch.sum(nr)\n",
    "        Q_mr = nr / (self.window_size - self.r + 1)\n",
    "        L_r = (Mr**2) * Q_mr / (Mr * Q_mr)**2\n",
    "\n",
    "        return L_r\n",
    "\n",
    "# Example usage:\n",
    "# Create an instance of the CustomPoolingLayer\n",
    "custom_pooling_layer = CustomPoolingLayer(r=3, window_size=3)\n",
    "\n",
    "# Assuming 'your_image_tensor' is your input tensor\n",
    "image = torch.tensor([[9, 11, 8, 20], [18, 18, 17, 3], [10, 7, 18, 16], [18, 17, 22, 13]], dtype=torch.float32)\n",
    "image = image.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Get the result using the custom pooling layer\n",
    "result = custom_pooling_layer(image)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch dimension stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        batch_size, channels, image_height, image_width = image.size()\n",
    "\n",
    "        # Initialize variables to accumulate results across batches\n",
    "        all_L_r = []\n",
    "\n",
    "        # Iterate over batches\n",
    "        for batch in range(batch_size):\n",
    "            # Extract the current batch's unfolded window\n",
    "            windows_horizontal = image[batch].unfold(1, self.window_size, 1).unfold(2, self.window_size, 1)\n",
    "            windows_horizontal = windows_horizontal.squeeze(0)\n",
    "\n",
    "            # Perform operations independently for each window in the current batch\n",
    "            max_pool = nn.MaxPool2d(kernel_size=self.window_size)\n",
    "            max_pool_output = max_pool(windows_horizontal)\n",
    "            min_pool_output = -max_pool(-windows_horizontal)\n",
    "\n",
    "            nr = torch.ceil(max_pool_output / self.r) - torch.ceil(min_pool_output / self.r) - 1\n",
    "            Mr = torch.sum(nr)\n",
    "            Q_mr = nr / (self.window_size - self.r + 1)\n",
    "            L_r = (Mr**2) * Q_mr / (Mr * Q_mr)**2\n",
    "\n",
    "            # Accumulate the result for the current batch\n",
    "            all_L_r.append(L_r)\n",
    "\n",
    "        # Concatenate results along the batch dimension\n",
    "        all_L_r = torch.cat(all_L_r, dim=0)\n",
    "\n",
    "        return all_L_r\n",
    "\n",
    "# Example usage:\n",
    "# Create an instance of the CustomPoolingLayer\n",
    "custom_pooling_layer = CustomPoolingLayer(r=3, window_size=3)\n",
    "\n",
    "\n",
    "image = torch.tensor([[9, 11, 8, 20], [18, 18, 17, 3], [10, 7, 18, 16], [18, 17, 22, 13]], dtype=torch.float32)\n",
    "image = image.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Get the result using the custom pooling layer\n",
    "result = custom_pooling_layer(image)\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel dimension stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        # Scale the input tensor to the range [0, 255]\n",
    "        image_scaled = image * 255.0\n",
    "\n",
    "        windows_horizontal = image_scaled.unfold(2, self.window_size, 1).unfold(3, self.window_size, 1)\n",
    "        windows_horizontal = windows_horizontal.squeeze(0).squeeze(0)\n",
    "\n",
    "        max_pool = nn.MaxPool2d(kernel_size=self.window_size)\n",
    "        max_pool_output = max_pool(windows_horizontal)\n",
    "        min_pool_output = -max_pool(-windows_horizontal)\n",
    "\n",
    "\n",
    "        nr = torch.ceil(max_pool_output / self.r) - torch.ceil(min_pool_output / self.r) - 1\n",
    "        Mr = torch.sum(nr)\n",
    "        Q_mr = nr / (self.window_size - self.r + 1)\n",
    "        L_r = (Mr**2) * Q_mr / (Mr * Q_mr)**2\n",
    "\n",
    "        return L_r\n",
    "\n",
    "# Example usage:\n",
    "# Create an instance of the CustomPoolingLayer\n",
    "custom_pooling_layer = CustomPoolingLayer(r=3, window_size=3)\n",
    "\n",
    "# Assuming 'your_image_tensor' is your input tensor with shape (1, 1, 4, 4)\n",
    "image = torch.rand((1, 1, 4, 4), dtype=torch.float32)\n",
    "\n",
    "# Get the result using the custom pooling layer\n",
    "result = custom_pooling_layer(image)\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized dimension stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0208]],\n",
      "\n",
      "         [[0.0145]],\n",
      "\n",
      "         [[0.0145]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0169]],\n",
      "\n",
      "         [[0.0137]],\n",
      "\n",
      "         [[0.0159]]],\n",
      "\n",
      "\n",
      "        [[[0.0149]],\n",
      "\n",
      "         [[0.0156]],\n",
      "\n",
      "         [[0.0152]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0169]],\n",
      "\n",
      "         [[0.0137]],\n",
      "\n",
      "         [[0.0141]]],\n",
      "\n",
      "\n",
      "        [[[0.0128]],\n",
      "\n",
      "         [[0.0167]],\n",
      "\n",
      "         [[0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0172]],\n",
      "\n",
      "         [[0.0185]],\n",
      "\n",
      "         [[0.0154]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0137]],\n",
      "\n",
      "         [[0.0135]],\n",
      "\n",
      "         [[0.0145]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0145]],\n",
      "\n",
      "         [[0.0145]],\n",
      "\n",
      "         [[0.0123]]],\n",
      "\n",
      "\n",
      "        [[[0.0133]],\n",
      "\n",
      "         [[0.0133]],\n",
      "\n",
      "         [[0.0147]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0145]],\n",
      "\n",
      "         [[0.0145]],\n",
      "\n",
      "         [[0.0123]]],\n",
      "\n",
      "\n",
      "        [[[0.0137]],\n",
      "\n",
      "         [[0.0137]],\n",
      "\n",
      "         [[0.0175]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0179]],\n",
      "\n",
      "         [[0.0179]],\n",
      "\n",
      "         [[0.0154]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        image_scaled = image * 255\n",
    "        batch_size, channels, image_height, image_width = image.size()\n",
    "\n",
    "        # Initialize variables to accumulate results across batches\n",
    "        all_L_r = []\n",
    "        all_L_r_channel = []\n",
    "\n",
    "        # Iterate over batches\n",
    "        for batch in range(batch_size):\n",
    "            # Iterate over channels\n",
    "            channel_L_r = []\n",
    "            for channel in range(channels):\n",
    "                # Extract the current batch's unfolded window for the current channel\n",
    "                windows_horizontal = image_scaled[batch, channel].unfold(0, self.window_size, 1).unfold(1, self.window_size, 1)\n",
    "                windows_horizontal = windows_horizontal.squeeze(0)\n",
    "\n",
    "                # Perform operations independently for each window in the current channel\n",
    "                max_pool = nn.MaxPool2d(kernel_size=self.window_size)\n",
    "                max_pool_output = max_pool(windows_horizontal)\n",
    "                min_pool_output = -max_pool(-windows_horizontal)\n",
    "\n",
    "                nr = torch.ceil(max_pool_output / self.r) - torch.ceil(min_pool_output / self.r) - 1\n",
    "                Mr = torch.sum(nr)\n",
    "                Q_mr = nr / (self.window_size - self.r + 1)\n",
    "                L_r = (Mr**2) * Q_mr / (Mr * Q_mr)**2\n",
    "                # Accumulate the result for the current channel\n",
    "                channel_L_r.append(L_r)\n",
    "\n",
    "            # Concatenate results along the channel dimension for the current batch\n",
    "            channel_L_r = torch.cat(channel_L_r, dim=0)\n",
    "            all_L_r_channel.append(channel_L_r)\n",
    "\n",
    "        # Concatenate results along the batch dimension\n",
    "        all_L_r_batch = torch.cat(all_L_r_channel, dim=1)\n",
    "\n",
    "        return all_L_r_batch\n",
    "\n",
    "# Example usage:\n",
    "# Create an instance of the CustomPoolingLayer\n",
    "custom_pooling_layer = CustomPoolingLayer(r=3, window_size=3)\n",
    "\n",
    "# Assuming 'your_image_tensor' is your input tensor with shape [128, 1, 13, 13] (128 batches, 1 channel, 13x13 image)\n",
    "image = torch.rand((128, 3, 13, 13), dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Get the result using the custom pooling layer\n",
    "result = custom_pooling_layer(image)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([1, 2, 1, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        image_scaled = image * 255\n",
    "        batch_size, channels, image_height, image_width = image.size()\n",
    "\n",
    "        # Initialize variables to accumulate results across batches\n",
    "        all_L_r = []\n",
    "\n",
    "        # Iterate over batches\n",
    "        for batch in range(batch_size):\n",
    "            # Iterate over channels\n",
    "            channel_L_r = []\n",
    "            for channel in range(channels):\n",
    "                # Extract the current batch's unfolded window for the current channel\n",
    "                windows_horizontal = image_scaled[batch, channel].unfold(0, self.window_size, 1).unfold(1, self.window_size, 1)\n",
    "                windows_horizontal = windows_horizontal.squeeze(0)\n",
    "\n",
    "                # Perform operations independently for each window in the current channel\n",
    "                max_pool = nn.MaxPool2d(kernel_size=self.window_size)\n",
    "                max_pool_output = max_pool(windows_horizontal)\n",
    "                min_pool_output = -max_pool(-windows_horizontal)\n",
    "\n",
    "                nr = torch.ceil(max_pool_output / self.r) - torch.ceil(min_pool_output / self.r) - 1\n",
    "                Mr = torch.sum(nr)\n",
    "                Q_mr = nr / (self.window_size - self.r + 1)\n",
    "                L_r = (Mr**2) * Q_mr / (Mr * Q_mr)**2\n",
    "\n",
    "                # Accumulate the result for the current channel\n",
    "                channel_L_r.append(L_r)\n",
    "\n",
    "            # Stack results across channels for the current batch\n",
    "            channel_L_r = torch.stack(channel_L_r, dim = 1)\n",
    "            all_L_r.append(channel_L_r)\n",
    "\n",
    "        # Stack results across batches\n",
    "        all_L_r = torch.stack(all_L_r)\n",
    "\n",
    "        return all_L_r\n",
    "    \n",
    "\n",
    "# Create an instance of the CustomPoolingLayer\n",
    "custom_pooling_layer = CustomPoolingLayer(r=3, window_size=3)\n",
    "\n",
    "# Assuming 'your_image_tensor' is your input tensor with shape [128, 1, 13, 13] (128 batches, 1 channel, 13x13 image)\n",
    "image = torch.rand((1, 1, 4, 4), dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Get the result using the custom pooling layer\n",
    "result = custom_pooling_layer(image)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        image_scaled = image * 255\n",
    "        batch_size, channels, image_height, image_width = image.size()\n",
    "\n",
    "        # Initialize variables to accumulate results across batches\n",
    "        all_L_r = []\n",
    "\n",
    "        # Iterate over batches\n",
    "        for batch in range(batch_size):\n",
    "            # Iterate over channels\n",
    "            channel_L_r = []\n",
    "            for channel in range(channels):\n",
    "                # Extract the current batch's unfolded window for the current channel\n",
    "                windows_horizontal = image_scaled[batch, channel].unfold(0, self.window_size, 1).unfold(1, self.window_size, 1)\n",
    "                # Perform operations independently for each window in the current channel\n",
    "                max_pool = nn.MaxPool2d(kernel_size=self.window_size)\n",
    "                max_pool_output = max_pool(windows_horizontal)\n",
    "                min_pool_output = -max_pool(-windows_horizontal)\n",
    "\n",
    "                nr = torch.ceil(max_pool_output / self.r) - torch.ceil(min_pool_output / self.r) - 1\n",
    "                Mr = torch.sum(nr)\n",
    "                Q_mr = nr / (self.window_size - self.r + 1)\n",
    "                L_r = (Mr**2) * Q_mr / (Mr * Q_mr)**2\n",
    "                L_r = L_r.squeeze(-1).squeeze(-1)\n",
    "                channel_L_r.append(L_r)\n",
    "\n",
    "            # Stack results along the channel dimension\n",
    "            channel_L_r = torch.stack(channel_L_r, dim=0)\n",
    "            all_L_r.append(channel_L_r)\n",
    "\n",
    "        # Stack results along the batch dimension\n",
    "        all_L_r = torch.stack(all_L_r, dim=0)\n",
    "        print(all_L_r.shape)\n",
    "\n",
    "        return all_L_r\n",
    "\n",
    "# Example usage\n",
    "custom_pooling = CustomPoolingLayer(r=3, window_size=3)\n",
    "input_data = torch.rand(1, 3, 4, 4)\n",
    "output = custom_pooling(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        m = nn.Softmax2d()\n",
    "        image = m(image) * 255\n",
    "        batch_size, channels, image_height, image_width = image.size()\n",
    "\n",
    "        # Perform operations independently for each window in the current channel\n",
    "        max_pool = nn.MaxPool2d(kernel_size=self.window_size, stride=1)\n",
    "        max_pool_output = max_pool(image)\n",
    "        min_pool_output = -max_pool(-image)\n",
    "\n",
    "        nr = torch.ceil(max_pool_output / self.r) - torch.ceil(min_pool_output / self.r) - 1\n",
    "        Mr = torch.sum(nr)\n",
    "        Q_mr = nr / (self.window_size - self.r + 1)\n",
    "        L_r = (Mr**2) * Q_mr / (Mr * Q_mr)**2\n",
    "        L_r = L_r.squeeze(-1).squeeze(-1)\n",
    "\n",
    "        return L_r\n",
    "\n",
    "image = torch.rand(3, 3, 4, 4)\n",
    "custom_pool = CustomPoolingLayer(r=3, window_size=3)\n",
    "result = custom_pool(image)\n",
    "\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/a/akshatha.mohan/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/grads/a/akshatha.mohan/anaconda3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Global_Lacunarity(nn.Module):\n",
    "    def __init__(self, dim=2, eps = 10E-6, scales = None, kernel = None, stride = None, padding = None):\n",
    "\n",
    "\n",
    "        # inherit nn.module\n",
    "        super(Global_Lacunarity, self).__init__()\n",
    "\n",
    "        # define layer properties\n",
    "        self.dim = dim\n",
    "        self.eps = eps\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.scales = scales\n",
    "        self.conv1x1 = nn.Conv2d(len(self.scales) * 3, 3, kernel_size=1)\n",
    "\n",
    "        #For each data type, apply two 1x1 convolutions, 1) to learn bin center (bias)\n",
    "        # and 2) to learn bin width\n",
    "        # Time series/ signal Data\n",
    "        if self.kernel is None:\n",
    "            if self.dim == 1:\n",
    "                self.gap_layer = nn.AdaptiveAvgPool1d(1)\n",
    "            \n",
    "            # Image Data\n",
    "            elif self.dim == 2:\n",
    "                self.gap_layer = nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "            # Spatial/Temporal or Volumetric Data\n",
    "            elif self.dim == 3:\n",
    "                self.gap_layer = nn.AdaptiveAvgPool3d(1)\n",
    "             \n",
    "            else:\n",
    "                raise RuntimeError('Invalid dimension for global lacunarity layer')\n",
    "        else:\n",
    "            if self.dim == 1:\n",
    "                self.gap_layer = nn.AvgPool1d((kernel[0]), stride=stride[0], padding=(0))\n",
    "            \n",
    "            # Image Data\n",
    "            elif self.dim == 2:\n",
    "                self.gap_layer = nn.AvgPool2d((kernel[0], kernel[1]), stride=(stride[0], stride[1]), padding=(0, 0))\n",
    "            \n",
    "            # Spatial/Temporal or Volumetric Data\n",
    "            elif self.dim == 3:\n",
    "                self.gap_layer = nn.AvgPool3d((kernel[0], kernel[1], kernel[2]), stride=(stride[0], stride[1], stride[2]), padding=(0, 0, 0))\n",
    "             \n",
    "            else:\n",
    "                raise RuntimeError('Invalid dimension for global lacunarity layer')\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #Compute squared tensor\n",
    "        #pdb.set_trace()\n",
    "        lacunarity_values = []\n",
    "        for scale in self.scales:\n",
    "            scaled_x = x * scale\n",
    "            squared_x_tensor = scaled_x ** 2\n",
    "\n",
    "            #Get number of samples\n",
    "            n_pts = np.prod(np.asarray(scaled_x.shape[-2:]))\n",
    "            if (self.kernel == None):\n",
    "                n_pts = np.prod(np.asarray(scaled_x.shape[-2:]))\n",
    "\n",
    "\n",
    "            #Compute numerator (n * sum of squared pixels) and denominator (squared sum of pixels)\n",
    "            L_numerator = ((n_pts)**2) * (self.gap_layer(squared_x_tensor))\n",
    "            L_denominator = (n_pts * self.gap_layer(scaled_x))**2\n",
    "\n",
    "            #Lacunarity is L_numerator / L_denominator - 1\n",
    "            L_r = (L_numerator / (L_denominator + self.eps)) - 1\n",
    "            lambda_param = 0.5 #boxcox transformation\n",
    "            y = (torch.pow(L_r.abs() + 1, lambda_param) - 1) / lambda_param\n",
    "\n",
    "            lacunarity_values.append(y)\n",
    "\n",
    "        result = torch.cat(lacunarity_values, dim=1)\n",
    "        reduced_output = self.conv1x1(result)\n",
    "        return reduced_output\n",
    "\n",
    "\n",
    "\n",
    "class CustomPoolingLayer(nn.Module):\n",
    "    def __init__(self, r=3, window_size=3, eps = 10E-6):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.r = r\n",
    "        self.window_size = window_size\n",
    "        self.normalize = nn.Softmax2d()\n",
    "        self.r_values = [0.015, 0.0625, 0.5, 0.25, 0.125, 0.2, 0.4, 0.3, 0.75, 0.6, 0.9, 0.8, 1]\n",
    "        self.num_output_channels = 3\n",
    "        self.eps = eps\n",
    "        self.conv1x1 = nn.Conv2d(len(self.r_values) * 3, self.num_output_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = self.normalize(image) * 255\n",
    "        L_r_all = []\n",
    "\n",
    "        # Perform operations independently for each window in the current channel\n",
    "        for r in self.r_values:\n",
    "            max_pool = nn.MaxPool2d(kernel_size=self.window_size, stride=1)\n",
    "            max_pool_output = max_pool(image)\n",
    "            min_pool_output = -max_pool(-image)\n",
    "\n",
    "            nr = torch.ceil(max_pool_output / r) - torch.ceil(min_pool_output / r) - 1\n",
    "            Mr = torch.sum(nr)\n",
    "            Q_mr = nr / (self.window_size - r + 1)\n",
    "            L_r = (Mr**2) * Q_mr / (Mr * Q_mr + self.eps)**2\n",
    "            L_r = L_r.squeeze(-1).squeeze(-1)\n",
    "            L_r_all.append(L_r)\n",
    "        channel_L_r = torch.cat(L_r_all, dim=1)\n",
    "        reduced_output = self.conv1x1(channel_L_r)\n",
    "\n",
    "        return reduced_output\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
